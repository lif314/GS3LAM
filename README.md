<p align="center">
  <h1 align="center">
    GS<sup>3</sup>LAM: Gaussian Semantic Splatting SLAM
    <br>
    [ACM MM 2024]
  </h1>
  <p align="center">
  <a href="https://github.com/lif314"><strong>Linfei Li</strong></a>
  Â·
  <a href="https://scholar.google.com/citations?user=8VOk_S4AAAAJ&hl=en"><strong>Lin Zhang*</strong></a>
  Â·
  <a href="https://scholar.google.com/citations?user=rrkp_usAAAAJ&hl=en"><strong>Zhong Wang</strong></a>
  Â·
  <a href="https://scholar.google.com/citations?user=A0N_mS0AAAAJ&hl=en"><strong>Ying Shen</strong></a>
</p>

  <h3 align="center"><a href="https://github.com/lif314/GS3LAM">ğŸŒProject page (comming soon)</a> 
  | <a href="https://dl.acm.org/doi/10.1145/3664647.3680739">ğŸ“Paper(ACM DL)</a>
  </h3>
  <div align="center"></div>
</p>

<p align="left">
  <a href="">
    <img src="./assets/teaser.png" alt="GS3LAM teaser" width="100%">
  </a>
</p>

<!-- <p align="center">
  <a href="">
    <img src="./assets/splatting_rendering.gif" alt="splatting" width="100%">
  </a>
  <a href="">
    <img src="./assets/o2_splatam_ours.gif" alt="o2_splatam_ours" width="100%">
  </a>
  <a href="">
    <img src="./assets/o3_splatam_ours.gif" alt="o3_splatam_ours" width="100%">
  </a>
  <a href="">
    <img src="./assets/r0_pointslam_ours.gif" alt="r0_pointslam_ours" width="100%">
  </a>
</p> -->

<!-- TABLE OF CONTENTS -->
<details open="open" style='padding: 10px; border-radius:5px 30px 30px 5px; border-style: solid; border-width: 1px;'>
  <summary>Table of Contents</summary>
  <ol>
    <li>
      <a href="#installation">Installation</a>
    </li>
    <li>
      <a href="#datasets">Datasets</a>
    </li>
    <li>
      <a href="#benchmarking">Benchmarking</a>
    </li>
    <li>
      <a href="#visualizer">Visualizer</a>
    </li>
    <li>
      <a href="#acknowledgement">Acknowledgement</a>
    </li>
    <li>
      <a href="#citation">Citation</a>
    </li>
  </ol>
</details>

## Installation

The simplest way to install all dependences is to use [anaconda](https://www.anaconda.com/) and [pip](https://pypi.org/project/pip/) in the following steps: 

```bash
conda create -n gs3lam python==3.10
conda activate gs3lam
conda install -c "nvidia/label/cuda-11.7.0" cuda-toolkit
pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117
pip install -r requirements.txt


# install Gaussian Rasterization
pip install submodules/gaussian-semantic-rasterization
```

## Datasets

DATAROOT is `./data` by default. Please change the `basedir` path in the scene-specific config files if datasets are stored somewhere else on your machine.

### Replica

The original Replica dataset does not contain semantic labels. We obtained semantic labels from [vMAP](https://github.com/kxhit/vMAP). You can download our generated semantic Replica dataset from [here](https://huggingface.co/datasets/3David14/GS3LAM-Replica), then place the data into the `./data/Replica` folder.

> Note, if you directly use the Replica dataset provided by vMAP, please modify the [Replica Dataloader](./src/datasets/replica.py) and the  [png_depth_scale](./configs/camera/replica.yaml) parameter in config files.

### TUM-RGBD

<!-- ç”±äºTUM-RGBDæ²¡æœ‰çœŸå€¼è¯­ä¹‰æ ‡ç­¾ï¼Œè¯¥æ•°æ®é›†å¹¶ä¸æ˜¯æˆ‘ä»¬çš„è¯„ä¼°æ•°æ®é›†ã€‚ä¸è¿‡ï¼Œä¸ºäº†æµ‹è¯•æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨DEVAç”Ÿæˆä¼ªè¯­ä¹‰æ ‡ç­¾ï¼Œæ‚¨å¯ä»¥ä»è¿™ä¸‹è½½å¸¦æœ‰è¯­ä¹‰æ ‡ç­¾çš„TUM-RGBDã€‚ä¸å¹¸çš„æ˜¯ï¼Œç°æœ‰è¯­ä¹‰åˆ†å‰²æ¨¡å‹éš¾ä»¥ä¿è¯é•¿åºåˆ—æ•°æ®çš„å¸§é—´è¯­ä¹‰ä¸€è‡´æ€§ï¼Œå› æ­¤æˆ‘ä»¬åªåœ¨fr1åºåˆ—ä¸Šè¿›è¡Œäº†æµ‹è¯•ã€‚ -->
The TUM-RGBD dataset does not have ground truth semantic labels, so it is not our evaluation dataset. However, in order to evalute the effectiveness of GS3LAM, we use pseudo-semantic labels generated by [DEVA](https://github.com/hkchengrex/Tracking-Anything-with-DEVA), which you can download from [here](https://huggingface.co/datasets/3David14/TUM-DEVA). Unfortunately, existing semantic segmentation models struggle to maintain inter-frame semantic consistency in long sequence data, so we only tested on the `freiburg1_desk` sequence.

### ScanNet

Please follow the data downloading procedure on the [ScanNet](http://www.scan-net.org/) website, and extract color/depth frames from the `.sens` file using this [code](https://github.com/ScanNet/ScanNet/blob/master/SensReader/python/reader.py).

<details>
  <summary>[Directory structure of ScanNet (click to expand)]</summary>

```
  DATAROOT
  â””â”€â”€ scannet
        â””â”€â”€ scene0000_00
            â””â”€â”€ frames
                â”œâ”€â”€ color
                â”‚   â”œâ”€â”€ 0.jpg
                â”‚   â”œâ”€â”€ 1.jpg
                â”‚   â””â”€â”€ ...
                â”œâ”€â”€ depth
                â”‚   â”œâ”€â”€ 0.png
                â”‚   â”œâ”€â”€ 1.png
                â”‚   â””â”€â”€ ...
                â”œâ”€â”€ label-filt
                â”‚   â”œâ”€â”€ 0.png
                â”‚   â”œâ”€â”€ 1.png
                â”‚   â””â”€â”€ ...
                â”œâ”€â”€ intrinsic
                â””â”€â”€ pose
                    â”œâ”€â”€ 0.txt
                    â”œâ”€â”€ 1.txt
                    â””â”€â”€ ...
```
</details>


We use the following sequences: 
```
scene0000_00
scene0059_00
scene0106_00
scene0169_00
scene0181_00
scene0207_00
```

## Benchmarking
### TUM-RGBD

To run GS3LAM on the `freiburg1_desk` scene, run the following command:

```bash
python run.py configs/Tum/tum_fr1.py
```

### Replica

To run GS3LAM on the `office0` scene, run the following command:

```bash
python run.py configs/Replica/office0.py
```

To run GS3LAM on all Replica scenes, run the following command:

```bash
bash scripts/eval_full_replica.sh
```

### ScanNet

To run GS3LAM on the `scene0059_00` scene, run the following command:

```bash
python run.py configs/Scannet/scene0059_00.py
```

To run GS3LAM on all ScanNet scenes, run the following command:

```bash
bash scripts/eval_full_scannet.bash
```

## Visualizer

### Online/Offline Reconstruction and Export Mesh

<!-- é¦–å…ˆï¼Œå®šä¹‰é…ç½®æ–‡ä»¶ä¸­çš„``SEED``å’ŒSCENE_NUMç¯å¢ƒå˜é‡ -->
- Define the ``SEED`` and ``SCENE_NUM`` environment variables in the configuration file.
```bash
# ``SEED`` is the random seed used during training, which should be consistent with the configuration.
export SEED=1

# ``SCENE_NUM`` is the index of the data sequence in the following list.
# Replica: ["room0", "room1", "room2","office0", "office1", "office2", "office3", "office4"]
# Scannet: ["scene0059_00", "scene0106_00", "scene0169_00", "scene0181_00", "scene0207_00", "scene0000_00"]
export SCENE_NUM=0
```

- Online reconstruction.
```bash
# optional mode: [color, depth, centers, sem, sem_color, sem_feature]
python visualizer/online_recon.py --mode color --logdir path/to/the/log
```

- Offline reconstruction.
```bash
# optional mode: [color, depth, centers, sem, sem_color, sem_feature]
python visualizer/offline_recon.py --mode sem_color --logdir path/to/the/log
```

- Export Mesh
```bash
# optional mode: [color, sem]
python visualizer/export_mesh.py --mode color --logdir path/to/the/log
```

### Plot Optimization Bias

To draw ``Fig. 2`` in the paper, which can demonstrate the relationship between optimization iterations, rendering quality and camera trajectories.

```bash
python visualizer/plot_opt_bias.py --logdir path/to/the/log
```

## Acknowledgement
We thank the authors of the following repositories for their open-source code:

- [3D Gaussian Splatting](https://github.com/graphdeco-inria/gaussian-splatting)
- [SplaTAM](https://github.com/spla-tam)
- [Gaussian-SLAM](https://github.com/VladimirYugay/Gaussian-SLAM)
- [vMAP](https://github.com/kxhit/vMAP)
- [Point-SLAM](https://github.com/eriksandstroem/Point-SLAM)
- [Gaussian Grouping](https://github.com/lkeab/gaussian-grouping)

## Citation

If you find our paper and code useful for your research, please use the following BibTeX entry.

```bibtex
@inproceedings{li2024gs3lam,
      author = {Li, Linfei and Zhang, Lin and Wang, Zhong and Shen, Ying},
      title = {GS3LAM: Gaussian Semantic Splatting SLAM},
      year = {2024},
      publisher = {Association for Computing Machinery},
      address = {New York, NY, USA},
      booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
      pages = {3019â€“3027},
      numpages = {9},
      location = {Melbourne VIC, Australia},
      series = {MM '24}
}
```